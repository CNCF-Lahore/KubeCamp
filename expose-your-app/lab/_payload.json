[{"data":1,"prerenderedAt":155},["Reactive",2],{"search-api":3},[4,11,19,27,37,45,56,65,75,80,89,93,104,108,118,122,133,137,143],{"id":5,"path":6,"dir":7,"title":8,"description":7,"keywords":9,"body":10},"content:0.index.md","/","","Home",[],"    The Bootcamp for Gaining Expertise in Kubernetes   The Kubernetes Mastery Bootcamp is a comprehensive, free training program that offers in-depth knowledge and hands-on experience in deploying, managing, and scaling containerized applications using Kubernetes. Participants will benefit from workshops, access to a sandbox environment for practical exercises, and training from industry experts.      5  Hands-on Explanation-based Kubernetes Labs  Dedicated Open Source   Kubernetes Sandbox  Dedicated Support From Kubernetes Experts  A Contibutor Level Access to Kubernetes Community Days 2024  Kubernetes Exam Voucher Worth 400$ -    Term & Conditions Applied  Linkedin Premium Voucher    Term & Conditions Applied        To access the mentioned Kubernetes Bootcamp benefits, please complete all requirements:      Join Slack   Join the CNCF Slack and stay updated with Kubernetes Trainings and Ask Questions from Kubernets Experts.   Join Here    Join Meetup   Join Meetup and stay updated with Kubernetes Workshops , Events & Trainings.   Join Here    Complete Workshop & Challenge   Complete Workshop lab using Kubernetes Free Sandbox , or alternative . To get started with guided hands-on labs ,   Click Here    Attending Kubernetes Community Days Lahore   To avail the perks, you have to join the Kubernetes Community Days to get yourself registered   Click Here    Share a word about Kubernetes Bootcamp & Kubernetes Community Days Lahore on social media   Sharing post and telling people about Kubernetes Community Days can increase your points and ranking    Fill the Google Form   After Completing all the above requirements , you have to fill the google form   Click Here",{"id":12,"path":13,"dir":14,"title":15,"description":16,"keywords":17,"body":18},"content:1.introduction:1.getting-started.md","/introduction/getting-started","introduction","Before We Begin","I'd like to share a story with you—a tale of the Kubernetes Community Days. This marks our second event, unfolding once again in Lahore, made possible by your invaluable support and the contributions of many to this vibrant ecosystem. As a team, we've poured our hearts and souls into this endeavor, driven by a fervent desire to empower our local community with knowledge and resources on Kubernetes. Before the inception of the Kubernetes Community Days, we realized a significant gap: many, including professionals, were unfamiliar with \"Kubernetes.\" Mentioning the name often elicited puzzled looks and curious questions: \"Kubernetes? What's that?\"",[],"  Before We Begin  I'd like to share a story with you—a tale of the Kubernetes Community Days. This marks our second event, unfolding once again in Lahore, made possible by your invaluable support and the contributions of many to this vibrant ecosystem. As a team, we've poured our hearts and souls into this endeavor, driven by a fervent desire to empower our local community with knowledge and resources on Kubernetes. Before the inception of the Kubernetes Community Days, we realized a significant gap: many, including professionals, were unfamiliar with \"Kubernetes.\" Mentioning the name often elicited puzzled looks and curious questions: \"Kubernetes? What's that?\"  Driven by our realization, we, a group of engineers, ventured into the realm of marketing. Our goal was to illuminate the benefits of Kubernetes, highlight job opportunities, and encourage contributions to the ecosystem. Our marketing efforts were creative and informative; we used memes to demystify Kubernetes and crafted posts and reels that significantly raised awareness. We reached out to potential sponsors, receiving mixed responses, but thankfully, companies like GitHub and Google Cloud stepped forward. Their support enabled us to host a high-quality, free event, complete with meals for all attendees at the Kubernetes Community Days Lahore 2023 edition.  Our efforts bore fruit, attracting over 300 developers to the University of Central Punjab and introducing them to Kubernetes technologies—a monumental achievement for our local community.  Post-event, we identified challenges and strategized solutions for the upcoming year. A notable issue was the accessibility of workshops; the cost of Sandbox labs, especially those based in the US, was prohibitive for many. Alternatives like Minikube or Kubeadm required intricate setups that could take hours. To address this, we've innovated a solution: a new, cost-free Sandbox. This tool enables anyone to set up a Kubernetes lab effortlessly. In the following section, we'll guide you on how to activate and make the most of your Sandbox.",{"id":20,"path":21,"dir":14,"title":22,"description":23,"keywords":24,"body":26},"content:1.introduction:2.Active-your-sandbox.md","/introduction/active-your-sandbox","Activate Your Sandbox","Before you begin, make sure you meet the following requirements:",[25],"Activate Your Kubernetes Sandbox","  Activate Your Sandbox  Before you begin, make sure you meet the following requirements:    GitHub Account : If you do not have a GitHub account, please   create a free account  before starting with the sandbox. This is essential for accessing the Kubernetes Sandbox environment.  Please ensure that no additional tabs are open to guarantee optimal performance. It is also important to verify that you have a stable internet connection.  We highly recommend using Google Chrome.  Activate Your Kubernetes Sandbox  To dive into the hands-on experience with Kubernetes, activate your Kubernetes Sandbox using GitHub Codespaces by clicking the button below:  Kubernetes Sanbox    Sandbox creation usually takes 2-3 minutes. In case it takes more time, please refresh your session.  Once the terminal is ready, please enter the following command so the Kubernetes cluster and node can be completely set up.     make   create\n  html .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}html.dark .shiki span {color: var(--shiki-dark);background: var(--shiki-dark-bg);font-style: var(--shiki-dark-font-style);font-weight: var(--shiki-dark-font-weight);text-decoration: var(--shiki-dark-text-decoration);}html .dark .shiki span {color: var(--shiki-dark);background: var(--shiki-dark-bg);font-style: var(--shiki-dark-font-style);font-weight: var(--shiki-dark-font-weight);text-decoration: var(--shiki-dark-text-decoration);}html .default .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}",{"id":28,"path":29,"dir":14,"title":30,"description":31,"keywords":32,"body":36},"content:1.introduction:3.what-you-will-learn.md","/introduction/what-you-will-learn","What You Will Learn","By the end of this bootcamp, you will have a solid understanding of what Kubernetes is and what it does. Specifically, you will learn how to:",[33,34,35],"Why Kubernetes?","Workshop Modules","Ready to Start?","  What You Will Learn  By the end of this bootcamp, you will have a solid understanding of what Kubernetes is and what it does. Specifically, you will learn how to:   Deploy, scale, update, and debug containerized applications on a Kubernetes cluster.  Utilize an interactive online terminal for real-world, practical application of your knowledge.  Why Kubernetes?  In today's digital landscape, users expect applications to be available 24/7, and developers are under pressure to deploy new versions of these applications multiple times a day. Kubernetes is designed to support this dynamic environment by enabling:    Continuous Deployment and Scaling : Release and update applications quickly and without downtime.   Efficient Resource Utilization : Intelligent scaling and resource management to meet user demand.   Reliability and Availability : Ensure that applications are always available to users.  Kubernetes combines Google's deep experience in running production loads at scale with the best-of-breed ideas and practices from the community.  Workshop Modules  Throughout this bootcamp, you will complete the following modules:     Create a Cluster : Learn the basics of Kubernetes clusters and how to set one up.    Deploy an App : Deploy your first application on Kubernetes.    Explore Your App : Understand how to inspect and interact with your deployed application.    Expose Your App Publicly : Make your application accessible from the internet.    Scale Up Your App : Adjust your application's resources to handle increased traffic.    Update Your App : Safely roll out updates to your application.  Ready to Start?  With everything set up and your understanding of the bootcamp structure, you're now ready to embark on your Kubernetes learning journey. Let's dive in and explore the powerful capabilities of Kubernetes together!",{"id":38,"path":39,"dir":14,"title":40,"description":41,"keywords":42,"body":44},"content:1.introduction:4.you-must-know.md","/introduction/you-must-know","Workshop Terms and Conditions and Usage Guidelines","Before proceeding with the workshop, it is crucial that all participants read, understand, and agree to the following terms and conditions and usage guidelines. Your participation in this workshop indicates your acceptance of these terms.",[43],"General Terms","  Workshop Terms and Conditions and Usage Guidelines  Before proceeding with the workshop, it is crucial that all participants read, understand, and agree to the following terms and conditions and usage guidelines. Your participation in this workshop indicates your acceptance of these terms.  General Terms    Limited Vouchers : We have a limited number of vouchers available for this workshop. Only participants who are passionate and complete all the required tasks and activities will be officially contacted and eligible for these vouchers.   Proper Use of Resources :   Abuse of the Kubernetes sandbox, including but not limited to, using it for hosting a personal website, mining for cryptocurrency, or engaging in hacking activities, will result in immediate termination of your services.  Participants must agree to the GitHub Codespaces terms and conditions. In the event of your GitHub account or service being terminated, CNCF Lahore & Team will not be involved or responsible for resolving such issues.   Respectful Behavior :   All participants are expected to conduct themselves in a professional and respectful manner at all times. Harassment, bullying, or discrimination of any kind will not be tolerated.  Any reports of inappropriate behavior will be taken seriously and may result in immediate expulsion from the workshop.   Confidentiality :   Some information and materials provided during the workshop may be confidential or proprietary. Participants agree not to disclose such information without explicit permission.",{"id":46,"path":47,"dir":48,"title":49,"description":7,"keywords":50,"body":55},"content:2.introduction-to-cluster:1.Creating-Cluster.md","/introduction-to-cluster/creating-cluster","introduction-to-cluster","Introduction to Kubernetes!",[51,52,53,54],"What is Kubernetes?","Understanding the Kubernetes Cluster","Getting Started","Ready, Set, Go!","  Introduction to Kubernetes!  What is Kubernetes?  Kubernetes, often abbreviated as K8s (with \"8\" representing the eight letters that are omitted), is an open-source platform designed to automate deploying, scaling, and operating application containers. It groups containers that make up an application into logical units for easy management and discovery. Kubernetes is built to run across a cluster of machines, providing a high level of availability.  Understanding the Kubernetes Cluster  A Kubernetes cluster consists of two main components:    Master : The brain behind the operation, coordinating the cluster.   Nodes : The workers, running your applications.  Cluster Diagram    This diagram illustrates how the master and nodes interact within a Kubernetes cluster.  Dive Deeper into the Components  The Master  The master is responsible for managing the cluster. It makes decisions about where to run applications based on resource availability and other scheduling criteria. It also handles scaling and updates to ensure the cluster operates smoothly.  Nodes  A node can be a virtual or physical machine, serving as the workhorse that runs your applications. Each node has the necessary tools to manage container operations, such as Docker, and is managed by the master. Nodes communicate with the master via the Kubernetes API, which the master exposes.  Why Kubernetes?  Kubernetes abstracts the hardware infrastructure, allowing applications to run on any node within the cluster without needing to be tied to specific machines. This flexibility significantly simplifies deploying, managing, and scaling applications.  Getting Started  For development purposes,   minikube  is a recommended tool. It simplifies the process of setting up a Kubernetes cluster by creating a VM on your local machine that hosts a single-node cluster. Minikube supports Linux, macOS, and Windows, offering an accessible way to start with Kubernetes.   Guess what we are using MiniKube with GitHubCodespaces for Kubernetes Sandbox.  The Name \"Kubernetes\"  Originating from Greek, Kubernetes means \"helmsman\" or \"pilot,\" highlighting its role in guiding and managing containerized applications.  Ready, Set, Go!  Now that you have a basic understanding of Kubernetes and its components, it's time to dive into the practical side.",{"id":57,"path":58,"dir":48,"title":59,"description":60,"keywords":61,"body":64},"content:2.introduction-to-cluster:2.Lab.md","/introduction-to-cluster/lab","Lab01 : Creating Your First Cluster","Creating your first cluster with a basic experience can be a bit challenging. Also, it is very dependent on your machine's hardware, because you need good RAM and memory to get started with Minikube or Kubeadm installation. If you have already activated your sandbox, please skip this lab. In case you are still struggling, then this is a step-by-step guide to help you activate your first cluster without a cost and depending on your hardware.",[25,62,63],"Creating a Cluster","Checking the Node","  Lab01 : Creating Your First Cluster  Creating your first cluster with a basic experience can be a bit challenging. Also, it is very dependent on your machine's hardware, because you need good RAM and memory to get started with Minikube or Kubeadm installation. If you have already activated your sandbox, please skip this lab. In case you are still struggling, then this is a step-by-step guide to help you activate your first cluster without a cost and depending on your hardware.  Before you begin, make sure you meet the following requirements:    GitHub Account : If you do not have a GitHub account, please   create a free account  before starting with the sandbox. This is essential for accessing the Kubernetes Sandbox environment.  Please ensure that no additional tabs are open to guarantee optimal performance. It is also important to verify that you have a stable internet connection.  We highly recommend using Google Chrome.  Activate Your Kubernetes Sandbox  If you already have an active Kubernetes Sandbox, please skip this step. In case you don't, please click the button below:  Kubernetes Sanbox   While conducting experiments, I found that Codespaces sometimes became slow. This issue was related to low memory and CPU, as well as poor internet connections. If you encounter any similar issues, try to ensure you have a good connection or consider refreshing your Codespace session.  Creating a Cluster  After opening the terminal and ensuring your connection is stable, you can initiate the creation of a control plane and node by entering the following command:     make   create\n  Checking the Node  After successfully executing the   make create  command, you can verify the status of the node by using the following command:     kubectl   get   nodes\n  This command will provide an output similar to the example below, showing the status, roles, age, and version of your nodes:     @adilshehzad786 ➜ /workspaces/Kubernetes-Playground (main) $ kubectl get nodes\n   NAME                       STATUS   ROLES                  AGE    VERSION\n   k3d-k3s-default-server-0   Ready    control-plane,master   3m6s   v1.21.3+k3s1\n  This output indicates that your Kubernetes node is ready and functioning correctly within the specified roles and version.  Upon execution, the process should resemble the screenshot below:   !ALTIMAGE    Congratulations, you have successfully completed Lab 01. Now it's time to deploy your first app.  html .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}html.dark .shiki span {color: var(--shiki-dark);background: var(--shiki-dark-bg);font-style: var(--shiki-dark-font-style);font-weight: var(--shiki-dark-font-weight);text-decoration: var(--shiki-dark-text-decoration);}html .dark .shiki span {color: var(--shiki-dark);background: var(--shiki-dark-bg);font-style: var(--shiki-dark-font-style);font-weight: var(--shiki-dark-font-weight);text-decoration: var(--shiki-dark-text-decoration);}html .default .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}",{"id":66,"path":67,"dir":68,"title":69,"description":70,"keywords":71,"body":74},"content:3.Deploy-an-App:1.Your-First-App.md","/deploy-an-app/your-first-app","deploy-an-app","Deploy Your First Application on Kubernetes","Welcome to the exciting journey of deploying your first application on a Kubernetes cluster! If you've ever wondered how modern applications ensure reliability and scalability, you're about to dive into one of the core practices that make it possible.",[72,73],"Understanding Deployments in Kubernetes","Let's Deploy Your First App!","  Deploy Your First Application on Kubernetes  Welcome to the exciting journey of deploying your first application on a Kubernetes cluster! If you've ever wondered how modern applications ensure reliability and scalability, you're about to dive into one of the core practices that make it possible.  Understanding Deployments in Kubernetes  Think of a   Deployment  in Kubernetes as your personal assistant for managing your application. It takes care of starting your app, making sure it's running on the cluster, and stepping in to fix things if something goes wrong. This is a big leap from the old days when applications were manually started, and if something failed, well, it was up to you to notice and fix it.  Deployments automate the process of managing your application instances across the cluster's Nodes (the machines running your app). If a Node encounters a problem, the Deployment is like a vigilant guardian that quickly replaces the affected instance, ensuring your service remains available.  The Self-Healing Mechanism  This self-healing mechanism is a game-changer. It means that your application can recover from hardware failures, maintenance, and other disruptions automatically. Deployments keep your app resilient and available, letting you sleep well at night knowing your app can take care of itself.  Let's Deploy Your First App!  Deploying an application on Kubernetes involves packaging your app into a container and telling Kubernetes how to run it. We'll use a simple NodeJS application as our example, but the concepts apply to any application you might want to deploy.  What You'll Need:    Kubectl : This is the command-line tool that lets you communicate with your Kubernetes cluster. Think of it as your bridge to the Kubernetes world.   This tool is already configured to your Sandbox   A Containerized Application : Your app needs to be packaged in a container format supported by Kubernetes. For our example, we'll use a Docker container.  The Application and Dockerfile  We've prepared a simple NodeJS application for you to deploy. You'll find the source code and the Dockerfile (the recipe for creating your app's container) in our GitHub repository:   [Insert URL to GitHub repo here]  This repository is your starting point. It contains everything you need to get your application running on Kubernetes.  Deploying the App    Prepare Your Application : Make sure your application is containerized and ready to go. If you're following our example, clone the GitHub repository to get the Dockerfile and source code.   Use Kubectl : With your application containerized, you'll use Kubectl to create a Deployment on your Kubernetes cluster. This process tells Kubernetes how to run your app, how many instances you want, and how to manage them.  Next Steps  Now that you have a basic understanding of what a Deployment is and how it works, it's time to put this knowledge into action. Head over to the tutorial to deploy your first app on Kubernetes. Follow the steps, and you'll see your application come to life on your very own Kubernetes cluster.  Happy deploying! 🚀",{"id":76,"path":77,"dir":68,"title":78,"description":7,"keywords":79,"body":7},"content:3.Deploy-an-App:2.Lab.md","/deploy-an-app/lab","Lab",[],{"id":81,"path":82,"dir":83,"title":84,"description":7,"keywords":85,"body":88},"content:4.Explore-Your-App:1.how-to-explore.md","/explore-your-app/how-to-explore","explore-your-app","How To Explore",[86,87],"Pods","Nodes","  Pods  In Module 2, the Deployment process creates a   Pod , which hosts your application instance. A Pod is essentially a group of one or more application containers (such as Docker or rkt), including shared storage (volumes), a unique cluster IP address, and information about how to run them (e.g., container image version or specific ports). Containers within a Pod share an IP address and port space, are always co-located and co-scheduled, and run in a shared context on the same node.  This setup models an application-specific “logical host” and contains one or more application containers that are relatively tightly coupled. For instance, alongside a NodeJS app container, a side container that feeds the data published by the webserver might be deployed within the same Pod. Prior to the era of containers, such applications would have run on the same physical or virtual machine.  Pods remain tied to the Node where they are deployed until they are terminated (according to their restart policy) or deleted. In the event of a Node failure, identical Pods are redeployed on other available Nodes. The Pod is considered the atomic deployment unit on the Kubernetes platform.    Nodes   Nodes  are the worker machines in Kubernetes, which can be either VMs or physical machines, depending on the cluster. Each Node is responsible for running Pods and is managed by the Master. The Master automatically schedules Pods based on the available resources on the Nodes.  Every Kubernetes Node runs at least:   A   container runtime  (such as containerd or CRI-O, not Docker as of recent Kubernetes versions) to pull and manage containers from a registry.   Kubelet , acting as a bridge between the Kubernetes Master and the Nodes, managing the Pods and the containers running on a machine.    Kubernetes and Container Runtimes  As of Kubernetes version 1.20, direct support for Docker as a container runtime has been deprecated due to Kubernetes' use of the Container Runtime Interface (CRI). The CRI allows Kubernetes to use a variety of container runtimes without needing to integrate them directly into the Kubernetes codebase. This move towards more flexible container runtime options enables Kubernetes to leverage runtimes like   containerd  and   CRI-O , which are designed to be simpler and more efficient than Docker for the specific needs of Kubernetes.  Exploring Pods and Nodes  To explore and manage Pods and Nodes in Kubernetes, you can use the following commands:   List all Pods in all namespaces:\n     kubectl   get   pods   --all-namespaces\n  List Pods in a specific namespace:\n     kubectl   get   pods   -n   \u003C  namespac  e  >\n  Describe a specific Pod to see its details:\n     kubectl   describe   pod   \u003C  pod-nam  e  >   -n   \u003C  namespac  e  >\n  List all Nodes in the cluster:\n     kubectl   get   nodes\n  Describe a specific Node to see its details, including running Pods and available resources:\n     kubectl   describe   node   \u003C  node-nam  e  >\n  html .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}html.dark .shiki span {color: var(--shiki-dark);background: var(--shiki-dark-bg);font-style: var(--shiki-dark-font-style);font-weight: var(--shiki-dark-font-weight);text-decoration: var(--shiki-dark-text-decoration);}html .dark .shiki span {color: var(--shiki-dark);background: var(--shiki-dark-bg);font-style: var(--shiki-dark-font-style);font-weight: var(--shiki-dark-font-weight);text-decoration: var(--shiki-dark-text-decoration);}html .default .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}",{"id":90,"path":91,"dir":83,"title":78,"description":7,"keywords":92,"body":7},"content:4.Explore-Your-App:2.Lab.md","/explore-your-app/lab",[],{"id":94,"path":95,"dir":96,"title":97,"description":7,"keywords":98,"body":103},"content:5.Expose-Your-App:1.How-to-make-it-public.md","/expose-your-app/how-to-make-it-public","expose-your-app","How To Make It Public",[99,100,101,102],"Introduction to Services","Types of Services","Exposing Pods Using Services","Using Labels for Organization and Selection","  Introduction to Services  In Kubernetes, while Pods are assigned their own unique IP addresses within the cluster, these IPs are not accessible from outside the Kubernetes environment. Given the dynamic nature of Pods—being terminated, deleted, or replaced—there needs to be a mechanism for continuous and automatic discovery among Pods and applications. This is where   Kubernetes Services  come into play, acting as an abstraction layer that groups Pods and allows for their exposure to external traffic, load balancing, and service discovery.  Key Concepts of Services    External Traffic Exposure : Services enable the exposure of Pods to traffic coming from outside the cluster.   Load Balancing : Services distribute incoming traffic among all the Pods that match its configuration, ensuring high availability and reliability.   Service Discovery : Services allow for the automatic discovery of Pods within the cluster, facilitating communication between different services, like a frontend webserver and a backend database.  Types of Services    LoadBalancer : Offers a public IP address for the service, making it accessible from outside the Kubernetes cluster. This is commonly used in cloud environments like Google Kubernetes Engine (GKE) or AWS.   NodePort : Exposes the service on a specific port across all Nodes of the cluster using Network Address Translation (NAT). This type is available on all Kubernetes clusters, including Minikube, and is useful for development and testing environments.  Exposing Pods Using Services  To expose your Pods to the outside world, you can create a Service. There are several ways to do this, depending on your requirements and the environment in which your Kubernetes cluster is running.  Creating a Service  You can expose your application by creating a Service. This is done using the   kubectl  command line. For example, to create a NodePort Service, you would use:     kubectl   expose   deployment   \u003C  deployment-nam  e  >   --type=NodePort   --name=  \u003C  service-name  >\n  This command creates a Service that exposes your Deployment on a specific port on each Node of the cluster.  Finding the Service IP and Port  After creating your Service, you can find the IP address and the port exposed by the Service using:     kubectl   get   services/  \u003C  service-nam  e  >\n  This will list the details of your service, including the NodePort assigned to your service if you've used the NodePort type.  Port Forwarding (Without Ingress or Load Balancer)  In cases where you don't have an Ingress controller or a LoadBalancer available, you can use port forwarding to access your application:     kubectl   port-forward   services/  \u003C  service-nam  e  >   \u003C  local-por  t  >  :  \u003C  service-por  t  >\n  This command forwards traffic from a local port on your machine to the service port on the cluster, allowing you to access the application via   localhost:\u003Clocal-port> .  Using Labels for Organization and Selection  Labels are key/value pairs attached to Kubernetes objects, like Pods, which can be used for organizing and selecting subsets of objects.  Attaching Labels  Labels can be attached at creation time or added to existing objects. They are useful for organizing objects in a meaningful way, such as by environment (  production ,   test ,   dev ), application version (  v1.2 ,   beta ), or service type (  frontend ,   backend ).  Selecting Pods with Services  When creating a Service, you can specify a Label Selector to match the Pods that the Service should manage. This is how a Service knows which Pods to expose and balance traffic across.  html .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}html.dark .shiki span {color: var(--shiki-dark);background: var(--shiki-dark-bg);font-style: var(--shiki-dark-font-style);font-weight: var(--shiki-dark-font-weight);text-decoration: var(--shiki-dark-text-decoration);}html .dark .shiki span {color: var(--shiki-dark);background: var(--shiki-dark-bg);font-style: var(--shiki-dark-font-style);font-weight: var(--shiki-dark-font-weight);text-decoration: var(--shiki-dark-text-decoration);}html .default .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}",{"id":105,"path":106,"dir":96,"title":78,"description":7,"keywords":107,"body":7},"content:5.Expose-Your-App:2.Lab.md","/expose-your-app/lab",[],{"id":109,"path":110,"dir":111,"title":112,"description":7,"keywords":113,"body":117},"content:6.Scale-Your-App:1.scale-In-and-Out.md","/scale-your-app/scale-in-and-out","scale-your-app","Scale In And Out",[114,115,116],"Understanding Scaling","How to Scale Your Application","Autoscaling (Beyond the Basics)","  Understanding Scaling  In this module, we delve into scaling your application within a Kubernetes environment. Scaling is a critical aspect of managing applications, ensuring they can handle varying loads of traffic. Kubernetes simplifies this process through Deployments and Services, enabling both scale-out (increasing the number of replicas) and scale-in (decreasing the number of replicas) operations.  Scaling in Kubernetes is primarily managed by adjusting the number of replicas in a Deployment. A replica represents an instance of your application running on a Pod. By increasing the number of replicas, you can scale out to handle more traffic. Conversely, reducing the number of replicas will scale in your application, reducing resources used when demand is lower.  Architecture of Scaling    Scaling Out (Up) : Creates new Pods and schedules them to Nodes with available resources, ensuring your application can handle increased load.   Scaling In (Down) : Removes Pods, reducing the number of instances to match the desired state, conserving resources.  Kubernetes Services play a crucial role in this process. A Service acts as a load balancer, distributing incoming traffic across all Pods of a Deployment. It continuously monitors the running Pods through endpoints, directing traffic only to available Pods, ensuring efficient load distribution and high availability.  How to Scale Your Application  Creating a Deployment with Multiple Replicas  You can specify the number of replicas at the creation of a Deployment:     kubectl   create   deployment   \u003C  deployment-nam  e  >   --image=  \u003C  image-name  >   --replicas=  \u003C  number-of-replicas  >\n  Scaling an Existing Deployment  To adjust the number of replicas for an existing Deployment, use the   kubectl scale  command:    Scaling Out : Increase the number of replicas     kubectl   scale   deployment   \u003C  deployment-nam  e  >   --replicas=  \u003C  desired-number-of-replicas  >\n   Scaling In : Decrease the number of replicas     kubectl   scale   deployment   \u003C  deployment-nam  e  >   --replicas=  \u003C  desired-number-of-replicas  >\n  \n    \n     Checking the Status of the Scaling Process  To monitor the status of your Deployment and the number of running replicas, use:     kubectl   get   deployments   \u003C  deployment-nam  e  >\n  This command provides information about the Deployment, including the desired and current number of replicas.  Autoscaling (Beyond the Basics)  While manual scaling provides control over the number of replicas, Kubernetes also supports autoscaling. This feature automatically adjusts the number of Pod replicas based on CPU usage or other metrics, although it's beyond the scope of this basic tutorial. Autoscaling ensures that your application has the resources it needs when demand spikes, without manual intervention.  html .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}html.dark .shiki span {color: var(--shiki-dark);background: var(--shiki-dark-bg);font-style: var(--shiki-dark-font-style);font-weight: var(--shiki-dark-font-weight);text-decoration: var(--shiki-dark-text-decoration);}html .dark .shiki span {color: var(--shiki-dark);background: var(--shiki-dark-bg);font-style: var(--shiki-dark-font-style);font-weight: var(--shiki-dark-font-weight);text-decoration: var(--shiki-dark-text-decoration);}html .default .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}",{"id":119,"path":120,"dir":111,"title":78,"description":7,"keywords":121,"body":7},"content:6.Scale-Your-App:2.Lab.md","/scale-your-app/lab",[],{"id":123,"path":124,"dir":125,"title":126,"description":7,"keywords":127,"body":132},"content:7.Update-Your-App:1.Rolling-up.md","/update-your-app/rolling-up","update-your-app","Rolling Up",[128,129,130,131],"Understanding Rolling Updates","Rolling Update Commands","Strategies for Zero Downtime Deployments","Summary","  Understanding Rolling Updates  Rolling updates are a fundamental feature in Kubernetes, enabling you to update the running version of your application seamlessly and without downtime. This approach is crucial for maintaining continuous availability, meeting the modern expectations of both users and developers for frequent updates.  A rolling update in Kubernetes incrementally replaces old Pods with new ones, which are based on a new version of the deployment image. This process ensures that the application remains available to users and that the update does not consume all resources, allowing for a balanced deployment.  Architecture and Workflow    Update Trigger : An update is triggered (usually by changing the Docker image version in a Deployment).   Pod Replacement : Kubernetes schedules new Pods with the new version while gradually terminating the old ones, ensuring that the service remains available throughout the process.   Resource Management : New Pods are only scheduled on Nodes with sufficient free resources, which optimizes resource use across the cluster.   Zero Downtime : Thanks to load balancing, users continue to access the service without interruption. The Service object in Kubernetes automatically redirects traffic to the available and updated Pods.  Requirements for Zero Downtime    Multiple Instances : Running multiple instances of your application is essential. This redundancy allows some Pods to be updated while others continue to serve user requests.   Proper Configuration : The Deployment must be properly configured to define the maximum number of Pods that can be unavailable and the maximum number of new Pods that can be created during the update.  Rolling Update Commands  Updating a Deployment  To perform a rolling update, you typically update the image of the Deployment. For example, to update an application to a new version, you use the following command:     kubectl   set   image   deployment/  \u003C  deployment-nam  e  >   \u003C  container-nam  e  >  =  \u003C  new-imag  e  >  :  \u003C  ta  g  >\n  This command sets a new image for the specified container within your Deployment. Kubernetes then starts a rolling update automatically.  Checking the Rollout Status  To monitor the status of the rollout, use:     kubectl   rollout   status   deployment/  \u003C  deployment-nam  e  >\n  This command provides real-time feedback on the progress of the update.  Rolling Back an Update  If something goes wrong, Kubernetes allows you to rollback to a previous state of the Deployment:     kubectl   rollout   undo   deployment/  \u003C  deployment-nam  e  >\n  This command reverts the Deployment to its previous state, leveraging Kubernetes' versioned update feature.  Strategies for Zero Downtime Deployments    Readiness Probes : Ensure your Pods have readiness probes configured. This makes Kubernetes only send traffic to Pods that are ready to handle requests.   Resource Limits : Define appropriate resource requests and limits to ensure that your containers have enough resources to run effectively but do not monopolize cluster resources.   Surge and Unavailability Settings : Customize the   maxSurge  and   maxUnavailable  settings in your Deployment configuration.   maxSurge  defines the maximum number of Pods that can be created above the desired number of Pods during an update.   maxUnavailable  defines the maximum number of Pods that can be unavailable during the update process.  Example Deployment Configuration for Rolling Updates  Here's a snippet of a Deployment manifest that specifies these parameters:     apiVersion  :   apps/v1\n   kind  :   Deployment\n   metadata  :\n     name  :   example-deployment\n   spec  :\n     replicas  :   3\n     strategy  :\n       type  :   RollingUpdate\n       rollingUpdate  :\n         maxSurge  :   1\n         maxUnavailable  :   1\n     selector  :\n       matchLabels  :\n         app  :   example\n     template  :\n       metadata  :\n         labels  :\n           app  :   example\n       spec  :\n         containers  :\n         -   name  :   example-container\n           image  :   example/image:v1\n           ports  :\n           -   containerPort  :   80\n  This configuration ensures a rolling update with at most one extra Pod beyond the desired count (  maxSurge ) and at most one Pod unavailable (  maxUnavailable ) at any time during the update process.  Summary  Rolling updates are a powerful feature of Kubernetes, allowing for continuous integration and delivery with zero downtime. By understanding and utilizing the concepts and commands outlined in this module, you can ensure that your applications remain available and responsive, even as you deploy updates and improvements.  html .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}html.dark .shiki span {color: var(--shiki-dark);background: var(--shiki-dark-bg);font-style: var(--shiki-dark-font-style);font-weight: var(--shiki-dark-font-weight);text-decoration: var(--shiki-dark-text-decoration);}html .dark .shiki span {color: var(--shiki-dark);background: var(--shiki-dark-bg);font-style: var(--shiki-dark-font-style);font-weight: var(--shiki-dark-font-weight);text-decoration: var(--shiki-dark-text-decoration);}html .default .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}",{"id":134,"path":135,"dir":125,"title":78,"description":7,"keywords":136,"body":7},"content:7.Update-Your-App:2.Lab.md","/update-your-app/lab",[],{"id":138,"path":139,"dir":125,"title":140,"description":7,"keywords":141,"body":142},"content:7.Update-Your-App:3.Quiz.md","/update-your-app/quiz","Quiz",[]," ",{"id":144,"path":145,"dir":146,"title":147,"description":148,"keywords":149,"body":154},"content:8.More:More-Resources.md","/more/more-resources","more","Kubernetes Learning Resources","A comprehensive guide to the best resources available for learning Kubernetes. This list includes courses, labs, cheat sheets, and eBooks, categorized by their access type (free or paid).",[150,151,152,153],"Courses","Labs","Cheat Sheets","eBooks","  Kubernetes Learning Resources  A comprehensive guide to the best resources available for learning Kubernetes. This list includes courses, labs, cheat sheets, and eBooks, categorized by their access type (free or paid).  Courses  Free    Kubernetes Basics  - Offered by the Kubernetes Official Website   An interactive tutorial that provides a basic understanding of Kubernetes system and its key components.   Kubernetes Basics   Introduction to Kubernetes  - Offered by edX   A beginner-friendly course that covers the fundamentals of Kubernetes, including its architecture, ecosystem, and core components.   Introduction to Kubernetes on edX  Paid    Kubernetes for Developers: Core Concepts  - Offered by Pluralsight   Focuses on how developers can utilize Kubernetes, covering deployment, managing applications, and understanding the core concepts of Kubernetes operations.   Kubernetes for Developers on Pluralsight   The Complete Kubernetes Course  - Offered by Udemy   A comprehensive course that covers Kubernetes from a beginner to advanced level, including running, deploying, and managing containers.   The Complete Kubernetes Course on Udemy   Kubernetes Hands-on Labs  - Offered by KodeKloud   KodeKloud provides an interactive learning experience with hands-on labs for Kubernetes, making it easier to understand and apply your knowledge in real-world scenarios.   Kubernetes Hands-on Labs on KodeKloud  Labs  Free    Katacoda - Kubernetes Playground   An interactive platform that offers free hands-on Kubernetes labs, allowing users to experiment with Kubernetes commands and deployments in a sandbox environment.   Katacoda Kubernetes Playground  Paid    Qwiklabs - Kubernetes in the Google Cloud   Offers detailed labs and quests that dive deep into deploying, managing, and scaling applications with Kubernetes on Google Cloud Platform.   Kubernetes in the Google Cloud on Qwiklabs  Cheat Sheets    Kubernetes Cheat Sheet by Denny Zhang   A comprehensive cheat sheet that covers essential Kubernetes commands and concepts, perfect for beginners and as a quick reference for experts.   Kubernetes Cheat Sheet   Official Kubernetes Cheat Sheet   Provided by the Kubernetes official documentation, this cheat sheet offers a quick reference to the most common Kubernetes commands and resources.   Official Kubernetes Cheat Sheet  eBooks  Free    Kubernetes Up & Running  - by Kelsey Hightower, Brendan Burns, and Joe Beda   Dive into the future of infrastructure management with this detailed guide to Kubernetes. Perfect for those looking to understand the application deployment and management at scale.   Kubernetes Up & Running   The Children's Illustrated Guide to Kubernetes   An engaging and highly visual eBook that introduces Kubernetes concepts through storytelling and illustrations, suitable for all ages.   Children's Illustrated Guide to Kubernetes",1708437243968]